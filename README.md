## Project Summary

<pdf_poster_final_presentation>

When people want to check the weather, they often have to rely on separate features and apps, such as search engines, widgets, or news apps, depending on the amount and quality of information they need. To address this inconvenience, we have developed a platform centered around **a chatbot function**, incorporating additional features like weather widgets and news. This allows users to check the weather forecast for today and the next five days, all in one place.

Furthermore, we aim to gradually improve the platform so that when users have **additional weather-related questions**, they can receive diverse and meaningful answers, such as recommendations for food or outfits, based on reliable standards.

We did not use pre-trained models or the Chat GPT API; instead, **we developed most of the project from scratch**. In particular, we created **our own templates** to provide dynamic weather data, enabling data generation and preprocessing. For the model, we **applied the attention mechanism** of transformers to better recognize weather-related keywords and time-sensitive labels.

## Main Functions

### Basic App Structure

<image_app_structure>

**Chat Tab**

→ Provides responses on 11 types of weather information (e.g., weather, temperature, highest temperature, precipitation probability, visibility). Beyond simple weather information, the chatbot offers answers related to the broader impact of weather across 37 categories (e.g., general weather, general temperature, food, clothing, etc.).

Example: "Will it be hot tomorrow afternoon?" → "The highest temperature tomorrow afternoon will be 28°C and the lowest will be 22°C. If you're sensitive to heat, we recommend dressing lightly."

Example 2: "What should I eat tomorrow?" → "The temperature tomorrow is expected to be 30.66°C. Therefore, we recommend cold cucumber soup, a dish often enjoyed in summer."

**Detailed Weather Tab**

→ Provides detailed weather information by region. This includes a brief description of the current weather, hour-by-hour forecasts for the day, and weather forecasts for the next five days.

**Weather News Tab**

→ By selecting a region or weather keyword, users can view six current news articles related to the keyword. Users can also view the full article or a three-sentence summary generated by a text-ranking model.

### Additional Features

**Convenience Store Map**

→ In case of questions related to rain, the app shows nearby convenience stores within a 1km radius based on the user's location, useful if they don't have an umbrella.

**Helpful Tips**

→ Occasionally, useful tips are provided alongside the weather responses, even if they are not directly related to the weather.

Example: "Should I turn on the air conditioner tomorrow?" → "The temperature tomorrow will be 31°C, with a high of 32°C and a low of 20°C. There is a risk of heatstroke, so please turn on the air conditioner as needed." + "Weathy's Tip: Using energy-saving mode can help you reduce electricity bills."

## System Pipeline

<image_pipeline>

<image_data1> <image_data2> <image_data3>

We used three different datasets.

First, to build a basic understanding of Korean grammar, we used 11,585 conversational data entries from AIHub, enabling the chatbot to engage in Korean dialogue.

Next, we created 6,142 custom questions and answers to help the model recognize different weather-related queries.

Example: "What will the weather be like at 2 AM tomorrow?" → "The weather tomorrow will be clear."

Example 2: "Will it be hot tomorrow?" → "The highest temperature tomorrow is expected to be 28°C."

Additionally, we created 3,008 entries of impact data to provide various interpretations of weather information.

Example: "I'm going golfing tomorrow, will it be windy?" → "The wind speed tomorrow is expected to be 8 km/h, so it should be a light breeze."

Afterwards, we proceeded with preprocessing and labeling the data.

We found that pre-trained models like BERT, which already contain some weather-related data, did not categorize weather as we intended. Therefore, we removed all weather-related conversations from the everyday data and moved forward. The model needed to generate a first response by recognizing the labeled data described below.

<image_template1> <image_template2> <image_template3>

We then labeled the data to create response structures using templates. We categorized the data into three main types: time, weather keywords, and impact.

Example: "What will the weather be like at 2 AM tomorrow?" → {date} {time period} {time} weather will be {weather}.

Example 2: "I'm going golfing tomorrow, will it be windy?" → The wind speed tomorrow will be {wind speed}. @@common wind speed@@

For time, we categorized the data into eight different groups, analyzing the structure of time-related queries.

Example: "What will the weather be like at 12 PM tomorrow / tomorrow afternoon / 12 PM?"

For weather, we categorized 11 different labels based on API-provided information.

Example: {weather}, {temperature}, …, {humidity}

For impact, we identified 37 labels, covering topics such as food, clothing, laundry, and air conditioning.

Example: @@common weather@@, @@common temperature@@, … @@detailed laundry@@, @@detailed clothing@@, @@detailed food@@

We trained the model using a transformer architecture. When asked weather-related questions, the model provides a first response that includes {weather keyword} and {impact}, which we then process further using templates to generate a complete response.

Example:

"Will it rain at 2 PM tomorrow?"

→ {date} {time} chance of precipitation is {precipitation probability}, and rainfall is expected to be {rainfall}. @@detailed rain@@ (generated by transformer)

→ "The chance of precipitation tomorrow at 2 PM is 70%, and rainfall is expected to be 10mm. Roads may be slippery, so please drive carefully." (Weather data input via API, date input from the question, impact response added using a template)

## Modeling

<image_model>

**Early Models of LLMs like GPT and BERT**

→ Implemented through basic models that were not pre-trained.

→ Useful for generating sentences autonomously, which is why they are adopted.

**Using Two Encoders and Two Decoders to Generate Sequences**

→ Improves sentence completeness by generating natural responses.

**Positional Encoding**

→ Learns by recognizing the position of each time-related label.

→ Provides real-time information in response to user questions.

**Self-Attention**

→ Recognizes key features of weather-related labels.

Example: "The wind speed tomorrow is 20 m/s" (wind speed = 20 m/s)

**Multi-Head Attention**

→ Independently extracts the importance of each time-related label.

Example: "The weather tomorrow at 9 AM will be clear."